{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ac4e4f",
   "metadata": {
    "papermill": {
     "duration": 0.005041,
     "end_time": "2022-08-08T11:34:51.295380",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.290339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MABP _ Multi Armed Bandit Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcdc0f",
   "metadata": {
    "papermill": {
     "duration": 0.003449,
     "end_time": "2022-08-08T11:34:51.302901",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.299452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e760733d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.313283Z",
     "iopub.status.busy": "2022-08-08T11:34:51.311882Z",
     "iopub.status.idle": "2022-08-08T11:34:51.416715Z",
     "shell.execute_reply": "2022-08-08T11:34:51.415566Z"
    },
    "papermill": {
     "duration": 0.11316,
     "end_time": "2022-08-08T11:34:51.419653",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.306493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Selection\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('../input/bandit/Ads_Optimisation.csv')\n",
    "\n",
    "# Implementing Random Selection\n",
    "import random\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "total_reward = 0\n",
    "for n in range(0, N): \n",
    "    ad = random.randrange(d)\n",
    "    ads_selected.append(ad)\n",
    "    reward = dataset.values[n, ad]\n",
    "    total_reward = total_reward + reward # total_reward  : 1251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621d540",
   "metadata": {
    "papermill": {
     "duration": 0.003673,
     "end_time": "2022-08-08T11:34:51.427293",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.423620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MAB에서는 모든 행동이 순서대로 발생한다 가정.\n",
    "\n",
    "그 순서에 따라 \n",
    "\n",
    "시점 $t$의 행동을 $A_t$라 하고, \n",
    "\n",
    "행동에 따른 보상은 $R_t$\n",
    "\n",
    "행동 $a$의 가치는 $q_*(a)$, \n",
    "\n",
    "시점 $t$에 추정된 가치는 $Q_t(a)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d9629a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.436818Z",
     "iopub.status.busy": "2022-08-08T11:34:51.436435Z",
     "iopub.status.idle": "2022-08-08T11:34:51.458622Z",
     "shell.execute_reply": "2022-08-08T11:34:51.457325Z"
    },
    "papermill": {
     "duration": 0.030551,
     "end_time": "2022-08-08T11:34:51.461689",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.431138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    0.121\n",
       "0    0.113\n",
       "5    0.111\n",
       "1    0.105\n",
       "3    0.099\n",
       "8    0.098\n",
       "6    0.096\n",
       "2    0.090\n",
       "7    0.086\n",
       "4    0.081\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ads_selected).tail(1000).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76025f",
   "metadata": {
    "papermill": {
     "duration": 0.003742,
     "end_time": "2022-08-08T11:34:51.469575",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.465833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Total reward for the random selection algorithm comes out to be 1170. As this algorithm is not learning anything, it will not smartly select any ad which is giving the maximum return. And hence even if we look at the last 1000 trials, it is not able to find the optimal ad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984223",
   "metadata": {
    "papermill": {
     "duration": 0.003617,
     "end_time": "2022-08-08T11:34:51.477214",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.473597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UCB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280babe",
   "metadata": {
    "papermill": {
     "duration": 0.003589,
     "end_time": "2022-08-08T11:34:51.484641",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.481052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "입실론-그리디 알고리즘은 최적의 주식을 찾기 위해 랜덤하게 탐험합니다. 그러나 이 랜덤성으로 인해서 최적값과는 멀어지기도 하고 탐색을 과도하게 하는 문제가 있습니다. 예를 들어, 10개의 행동 중 2개가 최선의 산황이여도 입실론-그리디 알고리즘은 나머지 8개도 공평하게 탐색하기 때문에 과도하게 탐색하는 문제가 발생합니다.\n",
    "\n",
    "이를 해결하기 위해 널리 쓰이는 방법 중 하나는 **UCB (Upper-Confidence-Bound) 알고리즘**입니다. \n",
    "\n",
    "\n",
    "**UCB (Upper-Confidence-Bound) 알고리즘**\n",
    "\n",
    "**알고리즘의 아이디어 :**\n",
    "\n",
    "     추정된 가치 $Q_t(a)$에서 일종의 신뢰 구간을 구해서 그 구간의 위쪽 신뢰 구간의 행동을 선택.\n",
    "\n",
    "**수식 :**\n",
    "$A_t = argmax_a [ Q_t(a) + c\\sqrt{\\frac{\\ln t}{N_t(a)}}]$\n",
    "\n",
    "- $t$는 현재 시점, \n",
    "\n",
    "- $N_t(a)$는 현재 시점까지 행동 $a$를 한 횟수\n",
    "\n",
    "일반적으로 신뢰구간을 구하는 식 $\\mu + c\\sqrt{\\sigma^2 / n}$에서 $\\mu$대신 $Q_t(a)$, $\\sigma^2$대신 $\\ln t$를 사용한 것만 다름을 알 수 있다.\n",
    "\n",
    " - 여기서 상수 $c$는 신뢰구간 폭을 제어하는 파라미터\n",
    "\n",
    "   -> $c$를 크게 하면 탐색을 많이 하게 되고 작게 하면 활용을 많이 하게 됨. 입실론-그리디 알고리즘에서 입실론이 크면 랜덤하게 탐색할 확률이 커지듯이 $c$도 값이 클수록 탐색을 많이 하게 됨.\n",
    "\n",
    " - $c\\sqrt{\\frac{\\ln t}{N_t(a)}}$항을 보면, $N_t(a)$를 분모에 두어 충분히 탐험되지 않은 행동에 가중치를 줌.\n",
    " \n",
    "   -> $N_t(a)$가 작을수록 $c\\sqrt{\\frac{\\ln t}{N_t(a)}}$)은 커지기 때문이죠! 결국 UCB 알고리즘에 들어가는 첫 번째 항 $Q_t(a)$은 활용 (Exploitation)에 중점을 둔 항이고, 두 번째 항 $c\\sqrt{\\frac{\\ln t}{N_t(a)}}$은 탐색 (Explotation)에 중점을 둔 항.\n",
    "   ->UCB 알고리즘은 활용과 탐색을 적절히 고려해서 선택하는 알고리즘이라 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeec2551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.493917Z",
     "iopub.status.busy": "2022-08-08T11:34:51.493523Z",
     "iopub.status.idle": "2022-08-08T11:34:51.698089Z",
     "shell.execute_reply": "2022-08-08T11:34:51.696790Z"
    },
    "papermill": {
     "duration": 0.212698,
     "end_time": "2022-08-08T11:34:51.701135",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.488437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing UCB\n",
    "import math\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_reward = [0] * d\n",
    "total_reward = 0\n",
    "\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if (numbers_of_selections[i] > 0):\n",
    "            average_reward = sums_of_reward[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(2 * math.log(n+1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if upper_bound > max_upper_bound:\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad) #선택된 ad (t 시점에서 upper bound가장 큰거) 10000행 1열\n",
    "    numbers_of_selections[ad] += 1 # 선택된 광고 댕긴 횟수 한 회 증가시키기\n",
    "    # numbers_of_selections은 10개의 광고 있으니까 ; [947, 417, 338, 380, 5630, 180, 435, 1106, 352, 215]\n",
    "\n",
    "    reward = dataset.values[n, ad]\n",
    "    sums_of_reward[ad] += reward # sums_of_reward : [176, 48, 31, 40, 1519, 1, 52, 217, 34, 7]\n",
    "    total_reward += reward # 2125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9092cb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.711179Z",
     "iopub.status.busy": "2022-08-08T11:34:51.710746Z",
     "iopub.status.idle": "2022-08-08T11:34:51.725521Z",
     "shell.execute_reply": "2022-08-08T11:34:51.724395Z"
    },
    "papermill": {
     "duration": 0.022898,
     "end_time": "2022-08-08T11:34:51.728217",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.705319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.771\n",
       "0    0.106\n",
       "7    0.034\n",
       "3    0.034\n",
       "2    0.026\n",
       "1    0.007\n",
       "6    0.007\n",
       "8    0.006\n",
       "9    0.005\n",
       "5    0.004\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ads_selected).tail(1000).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349344d",
   "metadata": {
    "papermill": {
     "duration": 0.003853,
     "end_time": "2022-08-08T11:34:51.736519",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.732666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After just 1500 trials, UCB is already favouring Ad #5 (index 4) which happens to be the optimal ad, and gets the maximum return for the given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941a419e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.746337Z",
     "iopub.status.busy": "2022-08-08T11:34:51.745906Z",
     "iopub.status.idle": "2022-08-08T11:34:51.753571Z",
     "shell.execute_reply": "2022-08-08T11:34:51.752283Z"
    },
    "papermill": {
     "duration": 0.015281,
     "end_time": "2022-08-08T11:34:51.755893",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.740612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77cbe8",
   "metadata": {
    "papermill": {
     "duration": 0.004107,
     "end_time": "2022-08-08T11:34:51.764328",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.760221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> ##  참고 한번에 합쳐 놓은 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9e18eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T11:34:51.774657Z",
     "iopub.status.busy": "2022-08-08T11:34:51.774205Z",
     "iopub.status.idle": "2022-08-08T11:34:52.085670Z",
     "shell.execute_reply": "2022-08-08T11:34:52.084359Z"
    },
    "papermill": {
     "duration": 0.320332,
     "end_time": "2022-08-08T11:34:52.088901",
     "exception": false,
     "start_time": "2022-08-08T11:34:51.768569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
      "0     1     0     0     0     1     0     0     0     1      0\n",
      "1     0     0     0     0     0     0     0     0     1      0\n",
      "2     0     0     0     0     0     0     0     0     0      0\n",
      "3     0     1     0     0     0     0     0     1     0      0\n",
      "4     0     0     0     0     0     0     0     0     0      0\n",
      "\n",
      "\n",
      "Random Selection\n",
      "\n",
      "\n",
      "8    0.125\n",
      "3    0.109\n",
      "5    0.102\n",
      "4    0.101\n",
      "0    0.099\n",
      "2    0.099\n",
      "7    0.099\n",
      "9    0.098\n",
      "1    0.087\n",
      "6    0.081\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Implementing UCB\n",
      "\n",
      "\n",
      "4    0.250000\n",
      "7    0.170667\n",
      "0    0.106000\n",
      "3    0.091333\n",
      "8    0.075333\n",
      "1    0.073333\n",
      "2    0.066000\n",
      "6    0.066000\n",
      "9    0.053333\n",
      "5    0.048000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dataset.head())\n",
    "# Implementing Random Selection\n",
    "print('\\n\\nRandom Selection\\n\\n')\n",
    "\n",
    "import random\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = random.randrange(d)\n",
    "    ads_selected.append(ad)\n",
    "    reward = dataset.values[n, ad]\n",
    "    total_reward = total_reward + reward\n",
    "\n",
    "\n",
    "print(pd.Series(ads_selected).tail(1000).value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# Implementing UCB\n",
    "print('\\n\\nImplementing UCB\\n\\n')\n",
    "import math\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_reward = [0] * d\n",
    "total_reward = 0\n",
    "\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if (numbers_of_selections[i] > 0):\n",
    "            average_reward = sums_of_reward[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(2 * math.log(n+1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if upper_bound > max_upper_bound:\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    numbers_of_selections[ad] += 1\n",
    "    reward = dataset.values[n, ad]\n",
    "    sums_of_reward[ad] += reward\n",
    "    total_reward += reward\n",
    "\n",
    "\n",
    "print(pd.Series(ads_selected).head(1500).value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.469592,
   "end_time": "2022-08-08T11:34:52.827022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-08T11:34:41.357430",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
